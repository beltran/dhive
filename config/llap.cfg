# Use lower case for the variable names!
# The way jinja2 works forces to do this atm

[global]
mysql_connector_version = 5.1.46

hadoop_version = 3.1.1
# hadoop_version = 3.2.0-SNAPSHOT

hive_version = 4.0.0-SNAPSHOT
tez_version = 0.10.1-SNAPSHOT

hive_path = /Users/jmarhuenda/workspace/hive
tez_path = /Users/jmarhuenda/workspace/tez


[core]

# Getting weird error: ERROR ApiServiceClient: User: yarn/rm.example.com@EXAMPLE.COM is not allowed to impersonate dr.who
hadoop.proxyuser.yarn.hosts = *
hadoop.proxyuser.yarn.groups = *
hadoop.http.staticuser.user = hive
# hadoop.kms.authentication.zk-dt-secret-manager.zkConnectionString = zk1.example.com:2181
# templeton.zookeeper.hosts = zk1.example.com:2181

hadoop.tmp.dir = /tmp/

[hdfs]


[yarn]

yarn.webapp.api-service.enable = true

# yarn.resourcemanager.zk-address = zk1.example.com:2181
# yarn.resourcemanager.placement-constraints.handler = scheduler

# If we set this two we have to modify the Yarnfile to make sure
# llap-DDMMMYYYY.tar.gz lands in the appropriate path
# yarn.service.framework.path = /user/yarn/framework
# yarn.service.base.path = /user/yarn/yarn

hadoop.registry.zk.quorum = zk1.example.com:2181
hadoop.registry.secure = true
hadoop.registry.system.acls = sasl:yarn@

yarn.resourcemanager.scheduler.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler

yarn.scheduler.capacity.root.queues=default,llap
yarn.scheduler.capacity.default.minimum-user-limit-percent=100
yarn.scheduler.capacity.maximum-am-resource-percent=100
yarn.scheduler.capacity.maximum-applications=10000
yarn.scheduler.capacity.node-locality-delay=40
yarn.scheduler.capacity.root.accessible-node-labels=*
yarn.scheduler.capacity.root.acl_administer_queue=yarn
yarn.scheduler.capacity.root.capacity=100
yarn.scheduler.capacity.root.default.acl_administer_jobs=yarn
yarn.scheduler.capacity.root.default.acl_submit_applications=yarn
yarn.scheduler.capacity.root.default.capacity=50
yarn.scheduler.capacity.root.default.maximum-capacity=50
yarn.scheduler.capacity.root.default.state=RUNNING
yarn.scheduler.capacity.root.default.user-limit-factor=2
yarn.scheduler.capacity.queue-mappings-override.enable=false
yarn.scheduler.capacity.root.acl_administer_jobs=yarn
yarn.scheduler.capacity.root.default.acl_administer_queue=yarn
yarn.scheduler.capacity.root.llap.acl_administer_queue=hive
yarn.scheduler.capacity.root.llap.acl_submit_applications=hive
yarn.scheduler.capacity.root.llap.capacity=50
yarn.scheduler.capacity.root.llap.maximum-am-resource-percent=1
yarn.scheduler.capacity.root.llap.maximum-capacity=50
yarn.scheduler.capacity.root.llap.minimum-user-limit-percent=100
yarn.scheduler.capacity.root.llap.ordering-policy=fifo
yarn.scheduler.capacity.root.llap.priority=10
yarn.scheduler.capacity.root.llap.state=RUNNING
yarn.scheduler.capacity.root.llap.user-limit-factor=2
yarn.scheduler.capacity.root.ordering-policy=priority-utilization


mapreduce.job.queuename = default
mapreduce.framework.name = yarn
mapreduce.cluster.local.dir = /tmp/
service_check.queue.name = default
yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor = 1
yarn.resourcemanager.placement-constraints.handler = scheduler

yarn.nodemanager.local-dirs = /tmp/

[tez]
tez.queue.name = llap
tez.am.node-blacklisting.enabled = false
tez.am.task.listener.thread-count = 1

tez.am.resource.memory.mb = 512
tez.runtime.io.sort.mb = 2048

tez.task-specific.log.level = DEBUG
tez.task.log.level = DEBUG
tez.am.log.level = DEBUG

tez.runtime.framework.local.dirs = /tmp/
mapreduce.cluster.local.dir = /tmp/
tez.runtime.enable.final-merge.in.output = true


[hive]

hive.llap.io.allocator.direct = false

templeton.hadoop.queue.name = default

hive.server2.enable.doAs = true
hive.warehouse.subdir.inherit.perms = true
hive.metastore.kerberos.principal = hive/_HOST@EXAMPLE.COM
hive.server2.tez.default.queues = default,llap
hive.server2.tez.sessions.per.default.queue = 4

hadoop.bin.path=/hadoop/bin/hadoop
hadoop.conf.path=/hadoop/etc/hadoop/

# hive.execution.mode = llap
hive.execution.mode = llap
hive.llap.execution.mode = all
hive.llap.daemon.service.hosts = @dhive-llap
hive.llap.auto.allow.uber = false
hive.llap.daemon.memory.per.instance.mb = 2048
hive.llap.daemon.num.executors = 4
hive.llap.daemon.task.scheduler.enable.preemption = true
hive.llap.io.enabled = true
hive.llap.io.threadpool.size = 20
hive.llap.task.scheduler.locality.delay = -1
hive.llap.task.scheduler.num.schedulable.tasks.per.node = -1
hive.llap.daemon.queue.name = llap

hive.llap.daemon.yarn.container.mb = 4096
hive.llap.daemon.vcpus.per.instance = 4
hive.llap.io.allocator.alloc.min = 1024
hive.llap.io.allocator.alloc.max = 2048
hive.llap.io.memory.size = 2048
hive.llap.task.scheduler.timeout.seconds = 60s
hive.llap.object.cache.enabled = true
hive.llap.io.use.lrfu = true
hive.llap.enable.grace.join.in.llap = false
hive.llap.client.consistent.splits = true

dfs.short.circuit.shared.memory.watcher.interrupt.check.ms = 0
dfs.client.mmap.enabled = false

hive.llap.daemon.work.dirs = /tmp/
hive.llap.daemon.keytab.file = /var/keytabs/hdfs.keytab
hive.llap.daemon.service.principal = hive/_HOST@EXAMPLE.COM
hive.llap.task.keytab.file = /var/keytabs/hdfs.keytab
hive.llap.task.principal = hive/_HOST@EXAMPLE.COM

hive.llap.daemon.service.ssl = false

hive.llap.zk.sm.principal = hive/zk1.example.com@EXAMPLE.COM
hive.llap.zk.sm.keytab.file = /var/keytabs/hdfs.keytab
hive.llap.zk.sm.connectionString = zk1.example.com:2181
hive.zookeeper.quorum = zk1.example.com:2181
hive.cluster.delegation.token.store.zookeeper.connectString = zk1.example.com:2181

zk-dt-secret-manager.zkConnectionString = zk1.example.com:2181
hive.cluster.delegation.token.store.zookeeper.acl = sasl:hive/zk1.example.com@EXAMPLE.COM:cdrwa
# hive.zookeeper.client.port = 2181
# templeton.zookeeper.hosts = zk1.example.com:2181

hive.llap.task.scheduler.am.registry.principal = hive/zk1.example.com@EXAMPLE.COM
hive.llap.task.scheduler.am.registry.keytab.file = /var/keytabs/hdfs.keytab

[hivemetastore]

hive.security.metastore.authorization.manager = org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
hive.security.metastore.authenticator.manager = org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.metastore.pre.event.listeners = org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
hive.metastore.execute.setugi = true

hive.warehouse.subdir.inherit.perms = true
# hive.users.in.admin.role = hive,hive_meta

# hive.stats.column.autogather = true
# hive.insert.into.multilevel.dirs = true

[services]
# Order is important
# The module file will be kerberos.yml, hadoop.yml, ...
services = kerberos,hadoop,yarn,tez,mysql,hive-meta,hive,llap,zookeeper
